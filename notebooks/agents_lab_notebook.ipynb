{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Agents Lab Notebook v1.0.0\nThis notebook contains steps and code to demonstrate the use of agents configured in Agent Lab in watsonx.ai. It introduces Python API commands for authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully. If code is modified or reordered, there is no guarantee it will successfully execute. For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Creating an agent with a set of tools using a specified model and parameters\n* Invoking the agent to generate a response \n\n# Setup\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# import dependencies\nfrom langchain_ibm import ChatWatsonx\nfrom ibm_watsonx_ai import APIClient\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.prebuilt import create_react_agent\nfrom ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\nimport json\nimport requests\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation Model inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import os\nimport getpass\n\ndef get_credentials():\n    return {\n        \"url\" : \"https://us-south.ml.cloud.ibm.com\",\n        \"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n    }\n\ndef get_bearer_token():\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n\n    response = requests.post(url, headers=headers, data=data)\n    return response.json().get(\"access_token\")\n\ncredentials = get_credentials()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Using the agent\nThese cells demonstrate how to create and invoke the agent with the selected models, tools, and parameters.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "model_id = \"meta-llama/llama-3-3-70b-instruct\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the result:\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "parameters = {\n    \"frequency_penalty\": 0,\n    \"max_tokens\": 2000,\n    \"presence_penalty\": 0,\n    \"temperature\": 0,\n    \"top_p\": 1\n}\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain the id from the project or space in which this notebook runs:\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Creating the agent\nWe need to create the agent using the properties we defined so far:\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n\n# Create the chat model\ndef create_chat_model():\n    chat_model = ChatWatsonx(\n        model_id=model_id,\n        url=credentials[\"url\"],\n        space_id=space_id,\n        project_id=project_id,\n        params=parameters,\n        watsonx_client=client,\n    )\n    return chat_model\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\ndef create_python_interpreter_tool(context):\n    from langchain_core.tools import StructuredTool\n\n    import ast\n    import sys\n    from io import StringIO\n    import uuid\n    import base64\n    import os\n\n    original_import = __import__\n\n    def get_image_url(base_64_content, image_name, context):\n        url = \"https://api.dataplatform.cloud.ibm.com\"\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f'Bearer {context.get_token()}'\n        }\n\n        body = {\n            \"name\": image_name,\n            \"blob\": base_64_content\n        }\n\n        params = {\n            \"project_id\": project_id\n        }\n\n        response = requests.post(f'{url}/wx/v1-beta/utility_agent_tools/resources', headers=headers, json=body, params=params)\n\n        return response.json().get(\"uri\")\n\n    def patched_import(name, globals=None, locals=None, fromlist=(), level=0):\n        module = original_import(name, globals, locals, fromlist, level)\n\n        if name == \"matplotlib.pyplot\":\n            sys.modules[\"matplotlib.pyplot\"].show = pyplot_show\n        return module\n\n    def pyplot_show():\n        pictureName = \"plt-\" + uuid.uuid4().hex + \".png\"\n        plt = sys.modules[\"matplotlib.pyplot\"]\n        plt.savefig(pictureName)\n        with open(pictureName, \"rb\") as image_file:\n            encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n            print(f\"base64image:{pictureName}:{str(encoded_string)}\")\n            os.remove(pictureName)\n            plt.clf()\n            plt.close(\"all\")\n\n    def init_imports():\n        import builtins\n        builtins.__import__ = patched_import\n\n    def _executeAgentCode(code):\n        old_stdout = sys.stdout\n        try:\n            full_code = \"init_imports()\\n\\n\" + code\n            tree = ast.parse(full_code, mode=\"exec\")\n            compiled_code = compile(tree, 'agent_code', 'exec')\n            namespace = {\"init_imports\": init_imports}\n            redirected_output = sys.stdout = StringIO(\"\")\n            exec(compiled_code, namespace)\n            value = redirected_output.getvalue()\n            if (value.startswith(\"base64image\")):\n                image_details = value.split(\":\")\n                image_name = image_details[1]\n                base_64_image = image_details[2]\n                image_url = get_image_url(base_64_image, image_name, context)\n                value = f\"Result of executing generated Python code is an image:\\n\\nIMAGE({image_url})\"\n        except Exception as e:\n            value = \"Error while executing Python code:\\n\\n\" + str(e)\n        finally:\n            sys.stdout = old_stdout\n        return value\n\n    tool_description = \"\"\"Run Python code and return the console output. Use for isolated calculations, computations or data manipulation. In Python, the following modules are available: Use numpy, pandas, scipy and sympy for working with data. Use matplotlib to plot charts. Other Python libraries are also available -- however, prefer using the ones above. Prefer using qualified imports -- `import library; library.thing()` instead of `import thing from library`. Do not attempt to install libraries manually -- it will not work. Do not use this tool multiple times in a row, always write the full code you want to run in a single invocation. If you get an error running Python code, try to generate a better one that will pass. If the tool returns result that starts with IMAGE(, follow instructions for rendering images.\"\"\"\n    tool_schema = {\n        \"type\": \"object\",\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"properties\": {\n            \"code\": {\n                \"description\": \"Code to be executed.\",\n                \"type\": \"string\"\n            }\n        },\n        \"required\": [\"code\"]\n    }\n\n    return StructuredTool(\n        name=\"PythonInterpreter\",\n        description = tool_description,\n        func=_executeAgentCode,\n        args_schema=tool_schema\n    )\n\n\nvector_index_id = \"40824957-150a-4607-a08c-7f8885b0befa\"\n\ndef create_rag_tool(vector_index_id, api_client):\n    config = {\n        \"vectorIndexId\": vector_index_id,\n        \"projectId\": project_id\n    }\n\n    tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about Mock Bank Policy Global\"\n\n    return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n\n\n\ndef create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n    from langchain_core.tools import StructuredTool\n    utility_agent_tool = Toolkit(\n        api_client=api_client\n    ).get_tool(tool_name)\n\n    tool_description = utility_agent_tool.get(\"description\")\n\n    if (kwargs.get(\"tool_description\")):\n        tool_description = kwargs.get(\"tool_description\")\n    elif (utility_agent_tool.get(\"agent_description\")):\n        tool_description = utility_agent_tool.get(\"agent_description\")\n\n    tool_schema = utility_agent_tool.get(\"input_schema\")\n    if (tool_schema == None):\n        tool_schema = {\n            \"type\": \"object\",\n            \"additionalProperties\": False,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"properties\": {\n                \"input\": {\n                    \"description\": \"input for the tool\",\n                    \"type\": \"string\"\n                }\n            }\n        }\n\n    def run_tool(**tool_input):\n        query = tool_input\n        if (utility_agent_tool.get(\"input_schema\") == None):\n            query = tool_input.get(\"input\")\n\n        results = utility_agent_tool.run(\n            input=query,\n            config=params\n        )\n\n        return results.get(\"output\")\n\n    return StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=run_tool,\n        args_schema=tool_schema\n    )\n\n\ndef create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n    from langchain_core.tools import StructuredTool\n    import ast\n\n    def call_tool(**kwargs):\n        tree = ast.parse(tool_code, mode=\"exec\")\n        custom_tool_functions = [x for x in tree.body if isinstance(x, ast.FunctionDef)]\n        function_name = custom_tool_functions[0].name\n        compiled_code = compile(tree, 'custom_tool', 'exec')\n        namespace = tool_params if tool_params else {}\n        exec(compiled_code, namespace)\n        return namespace[function_name](**kwargs)\n\n    tool = StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=call_tool,\n        args_schema=tool_schema\n    )\n    return tool\n\ndef create_custom_tools():\n    custom_tools = []\n\n    name_policy_retrieval_test_py_tfmz9 = \"policy_retrieval_test.py\"\n    desc_policy_retrieval_test_py_tfmz9 = \"\"\"Test\"\"\"\n    code_policy_retrieval_test_py_tfmz9 = \"\"\"import pytest\nimport time\n\n\n@pytest.fixture(scope=\"session\", autouse=True)\ndef refresh_token_before_tests():\n    from main_script import get_iam_token  # or the function you defined\n    global access_token\n    access_token = get_iam_token(\"YOUR_IBM_API_KEY\")\n    print(\"\n[Token refreshed before test session]\")\n    yield\n    print(\"\n[Tests complete; token expired naturally after session]\")\n\n\nimport os\nimport json\nimport datetime\nfrom textwrap import dedent\n\nimport requests\n\n\nwith open(\"evaluation_prompts.json\") as f:\n    eval_prompts = json.load(f)\n\n\nSYSTEM_PROMPT = dedent(\n    \"\"\"You are \"Loan Risk Assistant\", a bank-compliant copilot for loan officers and borrowers.\n\n## Mission\nGiven borrower/application details, produce:\n- A clear risk score summary (from the Risk Scoring API, not guessed)\n- Human-readable reasons (linked to policies/evidence)\n- Required docs to request next\n- A suggested interest-rate band (policy-constrained, not speculative)\n- Citations to policy chunks and retrieved docs\n- An audit payload for watsonx.governance\n\n## Tools available\n1) policy_docs_retriever(query, top_k)  \u2192 RAG over Docling\u2192Embeddings\u2192VectorDB\n2) risk_scoring_api(payload)            \u2192 Deterministic risk model; returns {score, features, reason_codes}\n3) get_policy_by_id(ids[])              \u2192 Fetch exact policy text for cited chunk_ids\n4) compose_user_packet(data)            \u2192 Format final packet for user delivery (HTML/text)\n5) request_additional_docs(list)        \u2192 Generate borrower request list in CRM\n6) governance_log(event_type, payload)  \u2192 Log every action (inputs, outputs, tool calls)\n\n## Ground rules\n- **Do not fabricate scores, policy text, or citations.** Always call the risk API for scores. Always cite chunk_ids returned by retrieval.\n- Prefer **bank policy** over model in case of conflict; call get_policy_by_id to confirm wording before quoting.\n- **Never reveal internal embeddings, prompt tokens, or staff-only notes** to end users.\n- **No personal advice** beyond bank policy; use neutral language.\n- If inputs are incomplete, **ask for the minimum next docs** required by policy, not everything.\n- Interest suggestion = **policy-bounded band**. If policy missing, return \"interest_rate_suggestion\": null and add a **policy_gap flag**.\n- Provide **short, skimmable** reasons with numbered bullets; each bullet must map to a reason_code or retrieved policy chunk.\n- Include **region + product** constraints when retrieving policies (e.g., state, product = {auto, mortgage, SMB term}, risk tiering rules).\n- **Log** each tool action with governance_log before returning the final response.\n\n## Required output format (JSON)\nReturn a single JSON object with:\n{\n  \"application_id\": \"<string>\",\n  \"risk_score\": { \"value\": <number>, \"scale\": \"0-100\", \"tier\": \"<Low|Med|High>\" },\n  \"reasons\": [\n    { \"label\": \"<short>\", \"detail\": \"<1-2 sentences>\", \"source\": {\"type\": \"policy|feature\", \"id_or_code\": \"<chunk_id|reason_code>\"} }\n  ],\n  \"policy_citations\": [\n    { \"chunk_id\": \"<id>\", \"title\": \"<doc title>\", \"section\": \"<sec>\", \"quote\": \"<<=50 words exact>>\" }\n  ],\n  \"requested_documents\": [\"<doc 1>\", \"<doc 2>\", \"...\"],\n  \"interest_rate_suggestion\": { \"band_apr_percent\": [min, max], \"basis\": \"<policy_ref>\", \"conditions\": [\"<e.g., auto-pay>\", \"...\"] } | null,\n  \"compliance\": {\n    \"region\": \"<state/country>\",\n    \"product\": \"<loan product>\",\n    \"policy_gap\": false\n  },\n  \"governance_log_ids\": [\"<id1>\", \"<id2>\", \"...\"],\n  \"user_packet\": { \"format\": \"html\", \"content\": \"<rendered summary for user>\" }\n}\n\n## Workflow\n1) Governance log: problem_received(application_id, redactions=true)\n2) Retrieve policies: policy_docs_retriever with product+region+keywords derived from the user input; cite chunk_ids.\n3) Score: risk_scoring_api with structured payload (income, DTI, FICO, LTV, collateral, delinq, purpose, term, region, product).\n4) Validate & enrich reasons: map reason_codes \u2192 plain language; cross-check against retrieved policy chunks; fetch exact quotes via get_policy_by_id for any cited chunk_ids you plan to quote.\n5) Decide **requested_documents**: enforce minimum-necessary principle from policy (e.g., proof of income variant depends on employment type).\n6) Interest band: derive from policy tables/logic; if insufficient policy evidence, set to null and set policy_gap=true.\n7) Compose user-facing packet; keep internal IDs out of user view. Write neutral, actionable language.\n8) Governance log each step (retrieval_done, risk_scored, packet_composed) with input/output hashes.\n9) Return the JSON object exactly once.\n\n## Style\n- Executive-brief length. 5\u20138 bullets max in reasons.\n- Cite policy chunks minimally (2\u20135), but precisely (section + <=50 words).\n- No speculative language. If uncertain, state what is missing and request docs.\n\nProceed when the user provides or updates application data.\"\"\"\n)\n\n\ndef test_policy_retrieval_api():\n    access_token = os.getenv(\"ACCESS_TOKEN\")\n    if not access_token:\n        raise RuntimeError(\"ACCESS_TOKEN environment variable must be set for this test\")\n\n    url = \"https://us-south.ml.cloud.ibm.com/ml/v1/text/chat?version=2023-05-29\"\n\n    model_id = \"ibm/granite-3-3-8b-instruct\"\n\n    for case in eval_prompts:\n        prompt_input = case[\"prompt\"]\n\n        body = {\n            \"messages\": [\n                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": prompt_input}\n                    ],\n                },\n            ],\n            \"project_id\": \"da24b80f-68d9-4b42-8c83-aaf5da05dcba\",\n            \"model_id\": model_id,\n            \"frequency_penalty\": 0,\n            \"max_tokens\": 2000,\n            \"presence_penalty\": 0,\n            \"temperature\": 0,\n            \"top_p\": 1,\n        }\n\n        response = requests.post(\n            url,\n            headers={\n                \"Accept\": \"application/json\",\n                \"Content-Type\": \"application/json\",\n                \"Authorization\": f\"Bearer {access_token}\",\n            },\n            json=body,\n            timeout=30,\n        )\n\n        if response.status_code != 200:\n            raise AssertionError(f\"Non-200 response: {response.text}\")\n\n        data = response.json()\n        model_response = data\n\n        log_entry = {\n            \"timestamp\": datetime.datetime.utcnow().isoformat(),\n            \"prompt\": prompt_input,\n            \"response\": model_response,\n            \"model\": model_id,\n            \"retrieval_index\": \"Mock Bank Policy Global\",\n        }\n\n        with open(\"policy_retrieval_logs.json\", \"a\") as f:\n            f.write(json.dumps(log_entry) + \"\n\")\n\n        print(f\"Prompt: {prompt_input}\")\n        print(f\"Response: {model_response}\n\")\n\n        assert isinstance(data, dict)\n\"\"\"\n    params_policy_retrieval_test_py_tfmz9 = {\n    }\n\n    schema_policy_retrieval_test_py_tfmz9 = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"prompt\": {\n                \"type\": \"string\",\n                \"title\": \"Policy query\",\n                \"description\": \"The natural-language question to ask the policy retrieval model\"\n            }\n        }\n    }\n    custom_tools.append(create_custom_tool(name_policy_retrieval_test_py_tfmz9, desc_policy_retrieval_test_py_tfmz9, code_policy_retrieval_test_py_tfmz9, schema_policy_retrieval_test_py_tfmz9, params_policy_retrieval_test_py_tfmz9))\n\n    return custom_tools\n\n\ndef create_tools(context):\n    tools = []\n    tools.append(create_rag_tool(vector_index_id, client))\n    tools.append(create_python_interpreter_tool(context))\n\n    config = None\n    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n\n    tools = tools + create_custom_tools()\n    return tools\n\ndef create_agent(context):\n    # Initialize the agent\n    chat_model = create_chat_model()\n    tools = create_tools(context)\n\n    memory = MemorySaver()\n    instructions = \"\"\"# Notes\n- When a tool is required to answer the user's query, respond only with <|tool_call|> followed by a JSON list of tools used.\n- If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\nYou are Loan Risk Assistant, an enterprise AI agent for evaluating loan applications\naccording to documented bank policies.\n\n## Purpose\nAssess risk, cite relevant policy rules, and produce a JSON report suitable for\nwatsonx.governance logging.\n\n## Responsibilities\n1. Compute a normalized risk score (0\u20131) with tier label (Low, Medium, High).\n2. Explain each reason concisely and cite the source policy section or reason code.\n3. Identify any required supporting documents.\n4. Suggest an interest-rate band only if the cited policy defines one.\n5. Always include compliance metadata (region, product, policy_gap flag).\nLoan Risk Tier Documentation Requirements\n1. LOW-RISK APPLICANTS (Low Tier)\n\nRequired Documents:\n\nValid Government-issued ID (for identity verification)\n\nPassport / Driver\u2019s License / National ID\n\nProof of Income (to confirm repayment ability)\n\nLatest 3 months\u2019 payslips\n\nCertificate of Employment (COE)\n\nBank statement showing salary credits (3 months)\n\nProof of Address (for KYC and correspondence)\n\nUtility bill or lease contract\n\nCredit Report or consent to pull one\n\nLoan Application Form (digitally filled and signed)\n\nCollateral Documents (if applicable)\n\nVehicle OR/CR, land title, or other asset proof\n\nSystem Behavior / Decision Logic:\n\nRisk Output: Accepted / Auto-approved (conditional)\n\nAction: Proceed to underwriting or direct approval if within policy thresholds\n\nAudit Log: System auto-logs approval with justification referencing risk score and compliance rules.\n\n2. HIGH-RISK APPLICANTS (High Tier)\n\nRequired Documents (Expanded Set):\n\nValid Government-issued ID\n\nProof of Income (Comprehensive):\n\nLatest 6 months of payslips or income statements\n\nIncome Tax Return (ITR) or Audited Financial Statement (for business owners/self-employed)\n\nBusiness Permit / DTI Certificate / SEC Registration (if applicable)\n\nProof of Address\n\nCollateral Documents (Mandatory for high-tier applicants):\n\nReal estate titles, vehicle ownership papers, or deposit certificates as security\n\nStatement of Assets and Liabilities (SALN or equivalent)\n\nBank Statements (last 6 months) \u2013 for cash flow verification\n\nGuarantor or Co-maker Agreement (if required by policy)\n\nSupporting Proof of Loan Purpose:\n\nPurchase order, contract, or business plan for loan justification\n\nProof of Capacity / Means to Pay:\n\nAdditional income sources (e.g., remittances, side business receipts, investment returns)\n\nLetter of Explanation (optional, to justify financial stability)\n\nSystem Behavior / Decision Logic:\n\nRisk Output: Denied (Flagged for manual review)\n\nAction: Temporarily marked as \u201cDenied \u2013 Awaiting Supporting Documents\u201d\n\nAudit Log: System records reason for denial and triggers a request for additional documentation.\n\nOnce additional proof is submitted and verified, the system can recalculate risk score or forward to manual credit officer review.\n\nf risk_tier == \"high\":\n    status = \"Denied (Pending Additional Proof)\"\n    required_docs = [\"ID\", \"Proof of Income (6 months)\", \"Collateral Docs\", \"ITR/Audited FS\", \"Bank Statements\", \"Guarantor Agreement\"]\nelse:\n    status = \"Accepted\"\n    required_docs = [\"ID\", \"Proof of Income (3 months)\", \"Proof of Address\"]\n\ngovernance_log(\"High-risk applicant flagged. Requesting additional proof of capacity.\")\n\n## OUTPUT\nOutput and then summarize the JSON in the chat while also giving approval or disapproval based on policy\n\n## Constraints\n- Never fabricate data, scores, or policy text.\n- Prefer policy evidence over model inference.\n- Use neutral, factual tone suitable for internal audit.\n- If data are incomplete, state what is missing and request only the minimum\n  additional documents.\n- Do not include user PII in outputs.\n- Log every inference using the governance client after completion.\n\nBe precise, transparent, and auditable.\n\"\"\"\n\n    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n\n    return agent\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Visualize the graph\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n\nImage(\n    create_agent(context).get_graph().draw_mermaid_png(\n        draw_method=MermaidDrawMethod.API,\n    )\n)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Invoking the agent\nLet us now use the created agent, pair it with the input, and generate the response to your question:\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "agent = create_agent(context)\n\ndef convert_messages(messages):\n    converted_messages = []\n    for message in messages:\n        if (message[\"role\"] == \"user\"):\n            converted_messages.append(HumanMessage(content=message[\"content\"]))\n        elif (message[\"role\"] == \"assistant\"):\n            converted_messages.append(AIMessage(content=message[\"content\"]))\n    return converted_messages\n\nquestion = input(\"Question: \")\n\nmessages = [{\n    \"role\": \"user\",\n    \"content\": question\n}]\n\ngenerated_response = agent.invoke(\n    { \"messages\": convert_messages(messages) },\n    { \"configurable\": { \"thread_id\": \"42\" } }\n)\n\nprint_full_response = False\n\nif (print_full_response):\n    print(generated_response)\nelse:\n    result = generated_response[\"messages\"][-1].content\n    print(f\"Agent: {result}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Next steps\nYou successfully completed this notebook! You learned how to use watsonx.ai inferencing SDK to generate response from the foundation model based on the provided input, model id and model parameters. Check out the official watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License. Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}