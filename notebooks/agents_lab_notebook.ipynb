{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25e9b00",
   "metadata": {},
   "source": [
    "# Agent Lab â€“ Clean Room Notebook\n",
    "\n",
    "This notebook mirrors the CLI experience documented in the repository and keeps the\n",
    "logic in sync with the reusable `agent_lab` package. Use it to experiment with the\n",
    "Loan Risk Assistant without duplicating boilerplate configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03164801",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "The notebook relies exclusively on the `agent_lab` module so any updates to the\n",
    "package (prompt tweaks, new tools, authentication fixes, etc.) are picked up here\n",
    "without manual copy/paste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74153f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Any, Iterable\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "from agent_lab import (\n",
    "    AgentContext,\n",
    "    DEFAULT_INSTRUCTIONS,\n",
    "    ModelConfig,\n",
    "    ModelParameters,\n",
    "    RagToolConfig,\n",
    "    Workspace,\n",
    "    build_agent,\n",
    "    load_credentials,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77772f9e",
   "metadata": {},
   "source": [
    "## 2. Helper utilities\n",
    "\n",
    "A couple of helpers keep the notebook tidy:\n",
    "\n",
    "* `resolve_workspace` mirrors the CLI logic so project/space IDs can come from either\n",
    "  the environment or ad-hoc overrides.\n",
    "* `convert_messages` adapts raw role/content dictionaries into LangChain objects for\n",
    "  seamless hand-off to the agent graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf93684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resolve_workspace(project_id: str | None = None, space_id: str | None = None) -> Workspace:\n",
    "    \"\"\"Load watsonx workspace identifiers with validation.\"\"\"\n",
    "\n",
    "    env_project_id = project_id or os.getenv(\"PROJECT_ID\") or os.getenv(\"WATSONX_PROJECT_ID\")\n",
    "    env_space_id = space_id or os.getenv(\"SPACE_ID\") or os.getenv(\"WATSONX_SPACE_ID\")\n",
    "\n",
    "    if not env_project_id and not env_space_id:\n",
    "        raise RuntimeError(\n",
    "            \"A watsonx project or space ID is required. Set PROJECT_ID/SPACE_ID (or their WATSONX_* variants).\"\n",
    "        )\n",
    "\n",
    "    return Workspace(project_id=env_project_id, space_id=env_space_id)\n",
    "\n",
    "\n",
    "def convert_messages(messages: Iterable[dict[str, Any]]):\n",
    "    converted_messages: list[HumanMessage | AIMessage] = []\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            converted_messages.append(AIMessage(content=message[\"content\"]))\n",
    "    return converted_messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd01bf2",
   "metadata": {},
   "source": [
    "## 3. Build the agent\n",
    "\n",
    "Credentials will be pulled from the environment (with an interactive fallback if the\n",
    "`IBM_API_KEY` variable is missing). Update the `vector_index_id` or model parameters to\n",
    "point at your own artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70022e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "credentials, source = load_credentials()\n",
    "workspace = resolve_workspace()\n",
    "\n",
    "rag_config = RagToolConfig(\n",
    "    vector_index_id=os.getenv(\"VECTOR_INDEX_ID\", \"40824957-150a-4607-a08c-7f8885b0befa\"),\n",
    ")\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_id=os.getenv(\"GRANITE_MODEL\", \"ibm/granite-3-3-8b-instruct\"),\n",
    "    parameters=ModelParameters(max_tokens=1500, temperature=0.1),\n",
    ")\n",
    "\n",
    "agent_context = AgentContext(\n",
    "    credentials=credentials,\n",
    "    workspace=workspace,\n",
    "    model=model_config,\n",
    "    instructions=DEFAULT_INSTRUCTIONS,\n",
    "    rag=rag_config,\n",
    ")\n",
    "\n",
    "agent = build_agent(agent_context)\n",
    "\n",
    "print(\"Agent ready. Credential source ->\", source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715085d0",
   "metadata": {},
   "source": [
    "## 4. Ask questions\n",
    "\n",
    "`run_notebook_prompt` wraps the invocation boilerplate so you can focus on the prompt\n",
    "engineering workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_notebook_prompt(prompt: str, *, thread_id: str = \"notebook-demo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = agent.invoke({\"messages\": convert_messages(messages)}, {\"configurable\": {\"thread_id\": thread_id}})\n",
    "    return response[\"messages\"][-1].content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942325d0",
   "metadata": {},
   "source": [
    "### Example query\n",
    "\n",
    "Feel free to edit the YAML payload or replace it with a free-form question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_prompt = \"\"\"high_risk:\n",
    "  applicant_id: 1001\n",
    "  risk_score: 0.85\n",
    "  credit_score: 580\n",
    "  debt_to_income: 0.62\n",
    "  explanation: \"Low credit score, high DTI\"\n",
    "\"\"\"\n",
    "\n",
    "print(run_notebook_prompt(sample_prompt))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
